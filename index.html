<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A Generative System for Robot-to-Human Handovers: from Intent Inference to Spatial Configuration Imagery.">
      <meta name="keywords" content="Human-Robot Collaboration, Intetion Recognition, Physical Human-Robot Interation">
      <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>A Generative System for Robot-to-Human Handovers: from Intent Inference to Spatial Configuration Imagery</title>

  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/index.js"></script>

<!-- Three.js and STL Viewer scripts for the interactive model -->
<script src="https://cdn.jsdelivr.net/npm/three@0.133.1/build/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.133.1/examples/js/controls/OrbitControls.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.133.1/examples/js/loaders/STLLoader.js"></script>
<script src="static/js/visualise_stl.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.133.1/examples/js/loaders/OBJLoader.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.133.1/examples/js/loaders/PLYLoader.js"></script>



</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">A Generative System for Robot-to-Human Handovers: from Intent Inference to Spatial Configuration Imagery</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="#">Hanxin Zhang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#">Abdulqader Dhafer</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#">Zhou Daniel Hao</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="#">Hongbiao Dong</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> DANiLab, School of
              Computing and Mathematical Sciences, University of Leicester, Leicester</span>
            <span class="author-block"><sup>2</sup>School of Engineering, University of Leicester</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2503.03579"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2503.03579"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=oSz2WZmWje4"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/figure_1.png"
           class="interpolation-image"
           alt="Interpolate start reference image."/>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" id="video">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose a novel system for robot-to-human object handover that emulates human coworker interactions. Unlike most existing studies that focus primarily on grasping strategies and motion planning, 
            our system focus on 1) inferring human handover intents, 2) imagining spatial handover configuration. The first one integrates multimodal perception—combining visual and verbal cues—to infer human intent. The second one using a diffusion-based model to generate the handover configuration, involving the spacial relationship among robot’s gripper, the object, and the human hand, thereby mimicking the cognitive process of motor imagery. Experimental results demonstrate that our approach effectively interprets human cues and achieves fluent, human-like handovers, offering a promising solution for collaborative robotics.           </p>
        </div>
      </div>
    </div>


    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/oSz2WZmWje4?rel=0&amp;showinfo=0"
            frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Mesh files Viewers -->
<section class="section">
  <div class="container is-max-desktop has-text-centered">
    <h2 class="title ">Interactive Diffusion Results</h2>
    <div class="content has-text-justified">
    <p>We applied the proposed generation method to various daily household items, producing results that define the spatial relationship between the robotic gripper, the object, and the human hand. The following are the visualization results.</p>
  </div>
    <div class="columns ">
      <div class="column">
        <div class="model-viewer" id="model-viewer1"></div>
      </div>
      <div class="column">
        <div class="model-viewer" id="model-viewer2"></div>
      </div>
    </div>
    <div class="columns ">
      <div class="column">
        <div class="model-viewer" id="model-viewer3"></div>
      </div>
      <div class="column">
        <div class="model-viewer" id="model-viewer4"></div>
      </div>
    </div>
    <div class="columns ">
      <div class="column">
        <div class="model-viewer" id="model-viewer5"></div>
      </div>
      <div class="column">
        <div class="model-viewer" id="model-viewer6"></div>
      </div>
    </div> 
  </div>
</section>


<script>
  initViewerObjPly('model-viewer1', './static/mesh/gamecontroller/gamecontroller_eef_0.obj', './static/mesh/gamecontroller/gamecontroller_right_hand_0.obj',  './static/mesh/gamecontroller/gamecontroller_right_hand_0.ply');
  initViewerObjPly('model-viewer2', './static/mesh/knife/knife_eef_0.obj', './static/mesh/knife/knife_right_hand_0.obj',  './static/mesh/knife/knife_right_hand_0.ply');
  initViewerObjPly('model-viewer3', './static/mesh/drill/drill_eef_0.obj', './static/mesh/drill/drill_right_hand_0.obj',  './static/mesh/drill/drill_right_hand_0.ply');
  initViewerObjPly('model-viewer4', './static/mesh/headphones/headphones_eef_0.obj', './static/mesh/headphones/headphones_right_hand_0.obj',  './static/mesh/headphones/headphones_right_hand_0.ply');
  initViewerObjPly('model-viewer5', './static/mesh/binoculars/binoculars_eef_0.obj', './static/mesh/binoculars/binoculars_right_hand_0.obj',  './static/mesh/binoculars/binoculars_right_hand_0.ply');
  initViewerObjPly('model-viewer6', './static/mesh/eyeglasses/eyeglasses_eef_0.obj', './static/mesh/eyeglasses/eyeglasses_right_hand_0.obj',  './static/mesh/eyeglasses/eyeglasses_right_hand_0.ply');

</script>
</script>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{zhang2025generativerobottohumanhandoversintent,
    title         = {A Generative System for Robot-to-Human Handovers: from Intent Inference to Spatial Configuration Imagery}, 
    author        = {Hanxin Zhang, Abdulqader Dhafer, Zhou Daniel Hao, Hongbiao Dong},
    year          = {2025},
    eprint        = {2503.03579},
    archivePrefix = {arXiv},
    primaryClass  = {cs.RO},
    url           = {https://arxiv.org/abs/2503.03579}, 
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
  
      <a class="icon-link" href="#" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We thank <a href="https://nerfies.github.io/"> <span class="dnerf">Nerfies</span></a> for sharing their template.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
