<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="A Generative System for Robot-to-Human Handovers: from Intent Inference to Spatial Configuration Imagery.">
      <meta name="keywords" content="Human-Robot Collaboration, Intetion Recognition, Physical Human-Robot Interation">
      <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>A Generative System for Robot-to-Human Handovers: from Intent Inference to Spatial Configuration Imagery</title>

  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/index.js"></script>

<!-- Three.js and STL Viewer scripts for the interactive model -->
<script src="https://cdn.jsdelivr.net/npm/three@0.133.1/build/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.133.1/examples/js/controls/OrbitControls.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.133.1/examples/js/loaders/STLLoader.js"></script>
<script src="static/js/visualise_stl.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.133.1/examples/js/loaders/OBJLoader.js"></script>
<script src="https://cdn.jsdelivr.net/npm/three@0.133.1/examples/js/loaders/PLYLoader.js"></script>



</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">A Generative System for Robot-to-Human Handovers: from Intent Inference to Spatial Configuration Imagery</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="#">Hanxin Zhang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#">Abdulqader Dhafer</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#">Zhou Daniel Hao</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="#">Hongbiao Dong</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> DANiLab, School of
              Computing and Mathematical Sciences, University of Leicester, Leicester</span>
            <span class="author-block"><sup>2</sup>School of Engineering, University of Leicester</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper (Coming Soon)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv (Coming Soon)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video (Coming Soon)</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/figure_1.png"
           class="interpolation-image"
           alt="Interpolate start reference image."/>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We propose a novel system for robot-to-human object handover that emulates human coworker interactions. Unlike most existing studies that focus primarily on grasping strategies and motion planning, 
            our system focus on 1) inferring human handover intents, 2) imagining spatial handover configuration. The first one integrates multimodal perception—combining visual and verbal cues—to infer human intent. The second one using a diffusion-based model to generate the handover configuration, involving the spacial relationship among robot’s gripper, the object, and the human hand, thereby mimicking the cognitive process of motor imagery. Experimental results demonstrate that our approach effectively interprets human cues and achieves fluent, human-like handovers, offering a promising solution for collaborative robotics.           </p>
        </div>
      </div>
    </div>

</section>


<!-- STL Viewer -->
<section class="section">
  <div class="container is-centered has-text-centered">
    <h2 class="title is-3">Interactive Diffusion Results</h2>
    <div class="columns">
      <div class="column has-text-centered">
        <div id="model-viewer" 
             style="width: 1000px; height: 500px; border: 1px solid #ccc; margin: 0 auto;">
        </div>
      </div>
    </div>
  </div>
</section>

<script>
  initViewerObjPly('model-viewer', './static/mesh/knife_eef_0.obj', './static/mesh/knife_right_hand_0.obj',  './static/mesh/knife_right_hand_0.ply');
</script>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
  
      <a class="icon-link" href="#" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We thank <a href="https://nerfies.github.io/"> <span class="dnerf">Nerfies</span></a> for sharing their template.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
